#!/usr/bin/env python3
"""
å­¤ç«‹æ–‡ä»¶æ¸…ç†è„šæœ¬ï¼šå®‰å…¨åˆ é™¤æ²¡æœ‰æ•°æ®åº“è®°å½•çš„æœ¬åœ°æ–‡ä»¶

æ­¤è„šæœ¬å°†ï¼š
1. æ‰«ææœ¬åœ°uploadsç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶
2. æ£€æŸ¥æ¯ä¸ªæ–‡ä»¶æ˜¯å¦åœ¨æ•°æ®åº“ä¸­æœ‰å¯¹åº”è®°å½•
3. å®‰å…¨åˆ é™¤å­¤ç«‹æ–‡ä»¶ï¼ˆæ²¡æœ‰æ•°æ®åº“è®°å½•çš„æ–‡ä»¶ï¼‰
4. ä¿ç•™æœ‰æ•°æ®åº“è®°å½•çš„æ–‡ä»¶
5. ç”Ÿæˆè¯¦ç»†çš„æ¸…ç†æŠ¥å‘Š
"""

import asyncio
import os
import sys
from pathlib import Path
from typing import List, Dict, Set
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent))

from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select

from app.core.config import settings
from app.core.database import async_session_maker
from app.models.invoice import Invoice
from app.utils.logger import get_logger

logger = get_logger(__name__)


class OrphanedFilesCleaner:
    """å­¤ç«‹æ–‡ä»¶æ¸…ç†å™¨"""
    
    def __init__(self):
        self.upload_dir = Path(settings.upload_dir)
        self.files_deleted = 0
        self.files_preserved = 0
        self.files_with_errors = 0
        self.total_space_freed = 0
        self.errors: List[Dict] = []
        self.deleted_files: List[Dict] = []
        self.preserved_files: List[Dict] = []
    
    async def scan_and_cleanup(self, dry_run: bool = True) -> Dict:
        """
        æ‰«æå¹¶æ¸…ç†å­¤ç«‹æ–‡ä»¶
        
        Args:
            dry_run: æ˜¯å¦ä¸ºè¯•è¿è¡Œæ¨¡å¼ï¼ˆä¸å®é™…åˆ é™¤æ–‡ä»¶ï¼‰
            
        Returns:
            Dict: æ¸…ç†ç»Ÿè®¡ä¿¡æ¯
        """
        logger.info(f"ğŸ” å¼€å§‹æ‰«æå­¤ç«‹æ–‡ä»¶ (dry_run={dry_run})")
        
        start_time = datetime.now()
        
        try:
            # 1. è·å–æ‰€æœ‰æœ¬åœ°æ–‡ä»¶
            local_files = await self._scan_local_files()
            logger.info(f"ğŸ“ å‘ç° {len(local_files)} ä¸ªæœ¬åœ°æ–‡ä»¶")
            
            # 2. è·å–æ•°æ®åº“ä¸­çš„æ‰€æœ‰æ–‡ä»¶è·¯å¾„
            db_file_paths = await self._get_database_file_paths()
            logger.info(f"ğŸ—„ï¸ æ•°æ®åº“ä¸­æœ‰ {len(db_file_paths)} ä¸ªæ–‡ä»¶è®°å½•")
            
            # 3. è¯†åˆ«å­¤ç«‹æ–‡ä»¶
            orphaned_files = self._identify_orphaned_files(local_files, db_file_paths)
            logger.info(f"ğŸ—‘ï¸ å‘ç° {len(orphaned_files)} ä¸ªå­¤ç«‹æ–‡ä»¶")
            
            # 4. åˆ é™¤å­¤ç«‹æ–‡ä»¶
            if not dry_run:
                await self._delete_orphaned_files(orphaned_files)
            else:
                logger.info("ğŸ” è¯•è¿è¡Œæ¨¡å¼ï¼šä¸ä¼šå®é™…åˆ é™¤æ–‡ä»¶")
                # åœ¨è¯•è¿è¡Œæ¨¡å¼ä¸‹ï¼Œåªç»Ÿè®¡ä¼šè¢«åˆ é™¤çš„æ–‡ä»¶
                for file_info in orphaned_files:
                    self.deleted_files.append({
                        'path': str(file_info['path']),
                        'size': file_info['size'],
                        'reason': 'orphaned_file'
                    })
                    self.total_space_freed += file_info['size']
                    self.files_deleted += 1
            
            # 5. ç»Ÿè®¡ä¿ç•™çš„æ–‡ä»¶
            preserved_files = self._identify_preserved_files(local_files, db_file_paths)
            for file_info in preserved_files:
                self.preserved_files.append({
                    'path': str(file_info['path']),
                    'size': file_info['size'],
                    'reason': 'has_database_record'
                })
                self.files_preserved += 1
        
        except Exception as e:
            logger.error(f"âŒ æ¸…ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            raise
        
        finally:
            # ç”ŸæˆæŠ¥å‘Š
            end_time = datetime.now()
            duration = end_time - start_time
            
            report = self._generate_report(duration, dry_run)
            logger.info("ğŸ“Š æ¸…ç†å®Œæˆï¼Œè¯¦ç»†æŠ¥å‘Š:")
            self._print_report(report)
            
            return report
    
    async def _scan_local_files(self) -> List[Dict]:
        """æ‰«ææœ¬åœ°æ–‡ä»¶"""
        local_files = []
        
        if not self.upload_dir.exists():
            logger.warning(f"ä¸Šä¼ ç›®å½•ä¸å­˜åœ¨: {self.upload_dir}")
            return local_files
        
        for file_path in self.upload_dir.rglob("*"):
            if file_path.is_file():
                try:
                    stat = file_path.stat()
                    relative_path = file_path.relative_to(self.upload_dir)
                    
                    local_files.append({
                        'path': file_path,
                        'relative_path': str(relative_path),
                        'size': stat.st_size,
                        'created_time': datetime.fromtimestamp(stat.st_ctime),
                        'modified_time': datetime.fromtimestamp(stat.st_mtime)
                    })
                except Exception as e:
                    logger.error(f"è¯»å–æ–‡ä»¶ä¿¡æ¯å¤±è´¥ {file_path}: {e}")
                    self.errors.append({
                        'file': str(file_path),
                        'error': str(e),
                        'operation': 'scan'
                    })
        
        return local_files
    
    async def _get_database_file_paths(self) -> Set[str]:
        """è·å–æ•°æ®åº“ä¸­çš„æ‰€æœ‰æ–‡ä»¶è·¯å¾„"""
        db_file_paths = set()
        
        async with async_session_maker() as session:
            stmt = select(Invoice.file_path).where(
                Invoice.file_path.is_not(None),
                Invoice.deleted_at.is_(None)
            )
            
            result = await session.execute(stmt)
            file_paths = result.scalars().all()
            
            for file_path in file_paths:
                if file_path:
                    db_file_paths.add(file_path)
        
        return db_file_paths
    
    def _identify_orphaned_files(self, local_files: List[Dict], db_file_paths: Set[str]) -> List[Dict]:
        """è¯†åˆ«å­¤ç«‹æ–‡ä»¶"""
        orphaned_files = []
        
        for file_info in local_files:
            relative_path = file_info['relative_path']
            
            # æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦åœ¨æ•°æ®åº“ä¸­
            if relative_path not in db_file_paths:
                orphaned_files.append(file_info)
        
        return orphaned_files
    
    def _identify_preserved_files(self, local_files: List[Dict], db_file_paths: Set[str]) -> List[Dict]:
        """è¯†åˆ«ä¿ç•™çš„æ–‡ä»¶"""
        preserved_files = []
        
        for file_info in local_files:
            relative_path = file_info['relative_path']
            
            # æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦åœ¨æ•°æ®åº“ä¸­
            if relative_path in db_file_paths:
                preserved_files.append(file_info)
        
        return preserved_files
    
    async def _delete_orphaned_files(self, orphaned_files: List[Dict]) -> None:
        """åˆ é™¤å­¤ç«‹æ–‡ä»¶"""
        logger.info(f"ğŸ—‘ï¸ å¼€å§‹åˆ é™¤ {len(orphaned_files)} ä¸ªå­¤ç«‹æ–‡ä»¶")
        
        for file_info in orphaned_files:
            try:
                file_path = file_info['path']
                file_size = file_info['size']
                
                # åˆ é™¤æ–‡ä»¶
                file_path.unlink()
                
                self.deleted_files.append({
                    'path': str(file_path),
                    'size': file_size,
                    'reason': 'orphaned_file'
                })
                self.total_space_freed += file_size
                self.files_deleted += 1
                
                logger.debug(f"âœ… åˆ é™¤æˆåŠŸ: {file_path}")
                
            except Exception as e:
                logger.error(f"âŒ åˆ é™¤å¤±è´¥ {file_info['path']}: {e}")
                self.errors.append({
                    'file': str(file_info['path']),
                    'error': str(e),
                    'operation': 'delete'
                })
                self.files_with_errors += 1
    
    def _generate_report(self, duration, dry_run: bool) -> Dict:
        """ç”Ÿæˆæ¸…ç†æŠ¥å‘Š"""
        return {
            'summary': {
                'dry_run': dry_run,
                'files_deleted': self.files_deleted,
                'files_preserved': self.files_preserved,
                'files_with_errors': self.files_with_errors,
                'total_space_freed_mb': round(self.total_space_freed / (1024 * 1024), 2),
                'duration_seconds': round(duration.total_seconds(), 2)
            },
            'deleted_files': self.deleted_files,
            'preserved_files': self.preserved_files,
            'errors': self.errors
        }
    
    def _print_report(self, report: Dict) -> None:
        """æ‰“å°æ¸…ç†æŠ¥å‘Š"""
        summary = report['summary']
        
        print("\n" + "="*60)
        print("ğŸ“Š æ–‡ä»¶æ¸…ç†æŠ¥å‘Š")
        print("="*60)
        print(f"ğŸ” è¿è¡Œæ¨¡å¼: {'è¯•è¿è¡Œ' if summary['dry_run'] else 'å®é™…æ‰§è¡Œ'}")
        print(f"ğŸ—‘ï¸ åˆ é™¤æ–‡ä»¶: {summary['files_deleted']} ä¸ª")
        print(f"ğŸ’¾ ä¿ç•™æ–‡ä»¶: {summary['files_preserved']} ä¸ª")
        print(f"âŒ é”™è¯¯æ–‡ä»¶: {summary['files_with_errors']} ä¸ª")
        print(f"ğŸ“¦ é‡Šæ”¾ç©ºé—´: {summary['total_space_freed_mb']} MB")
        print(f"â±ï¸ æ‰§è¡Œæ—¶é—´: {summary['duration_seconds']} ç§’")
        
        if self.deleted_files:
            print(f"\nğŸ—‘ï¸ åˆ é™¤çš„æ–‡ä»¶ (æ˜¾ç¤ºå‰10ä¸ª):")
            for file_info in self.deleted_files[:10]:
                size_mb = round(file_info['size'] / (1024 * 1024), 2)
                print(f"  â€¢ {file_info['path']} ({size_mb} MB)")
        
        if self.preserved_files:
            print(f"\nğŸ’¾ ä¿ç•™çš„æ–‡ä»¶ (æ˜¾ç¤ºå‰5ä¸ª):")
            for file_info in self.preserved_files[:5]:
                size_mb = round(file_info['size'] / (1024 * 1024), 2)
                print(f"  â€¢ {file_info['path']} ({size_mb} MB)")
        
        if self.errors:
            print(f"\nâŒ é”™è¯¯è¯¦æƒ…:")
            for error in self.errors[:5]:
                print(f"  â€¢ {error['file']}: {error['error']}")
        
        print("="*60)


async def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="æ¸…ç†å­¤ç«‹çš„ä¸Šä¼ æ–‡ä»¶")
    parser.add_argument(
        '--execute', 
        action='store_true', 
        help='å®é™…æ‰§è¡Œåˆ é™¤æ“ä½œï¼ˆé»˜è®¤ä¸ºè¯•è¿è¡Œï¼‰'
    )
    parser.add_argument(
        '--confirm', 
        action='store_true', 
        help='ç¡®è®¤æ‰§è¡Œåˆ é™¤æ“ä½œ'
    )
    
    args = parser.parse_args()
    
    # å®‰å…¨æ£€æŸ¥
    if args.execute and not args.confirm:
        print("âŒ è¦æ‰§è¡Œå®é™…åˆ é™¤æ“ä½œï¼Œå¿…é¡»åŒæ—¶æŒ‡å®š --execute å’Œ --confirm å‚æ•°")
        print("   ç¤ºä¾‹: python cleanup_orphaned_files.py --execute --confirm")
        return False
    
    try:
        cleaner = OrphanedFilesCleaner()
        
        # æ‰§è¡Œæ¸…ç†
        dry_run = not (args.execute and args.confirm)
        report = await cleaner.scan_and_cleanup(dry_run=dry_run)
        
        if dry_run:
            print("\nğŸ” è¿™æ˜¯è¯•è¿è¡Œæ¨¡å¼ã€‚è¦å®é™…åˆ é™¤æ–‡ä»¶ï¼Œè¯·ä½¿ç”¨:")
            print("   python cleanup_orphaned_files.py --execute --confirm")
        
        return report['summary']['files_with_errors'] == 0
        
    except Exception as e:
        logger.error(f"âŒ æ¸…ç†å¤±è´¥: {e}")
        return False


if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)